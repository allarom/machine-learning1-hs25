---
title: "Used Cars – Applied ML Project"
output:
  html_document:
    css: "styles.css"
---

<!-- Load libraries -->
```{r setup, message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(here)
```

# About the Dataset (Summary)

The Used Car Price Prediction dataset contains 4,009 vehicle listings collected from the automotive marketplace cars.com.
Each row represents a unique car and includes nine key attributes relevant to pricing and vehicle characteristics.
Dataset is taken from Kaggle: https://www.kaggle.com/datasets/taeefnajib/used-car-price-prediction-dataset

The dataset provides information on:

**Brand and model** – manufacturer and specific vehicle model

**Model year ** – age of the car, influencing depreciation

**Mileage** – an indicator of usage and wear

**Fuel type** – e.g., gasoline, diesel, electric, hybrid

**Engine type** – performance and efficiency characteristics

**Transmission** – automatic or manual

**Exterior/interior colors** – aesthetic properties

**Accident history** – whether the car has previously been damaged

**Clean title** – legal/ownership status

**Price** – listed price of the vehicle

Overall, the dataset offers a structured overview of key features that influence used car valuation. It is well-suited for analytical tasks such as understanding pricing drivers, exploring consumer preferences, and building predictive models for vehicle prices.
# Raw data

We load the original CSV directly from the project data folder using `here()` so paths work regardless of the working directory.

```{r load-raw, message=FALSE}
raw_path <- here("data", "raw", "used_cars.csv")
cars_raw <- readr::read_csv(raw_path, show_col_types = FALSE)
```

Basic structure and summary statistics of the raw dataset:

```{r raw-summary}
glimpse(cars_raw)
```

# Exploratory Data Analysis

We base the EDA on the engineered dataset (`data/processed/used_cars_features.csv`) that keeps cleaned numeric fields and derived features like age, mileage in thousands, and accident flags.

```{r load-features, message=FALSE}
features_path <- here("data", "processed", "used_cars_features.csv")
cars <- readr::read_delim(features_path, delim = ";", show_col_types = FALSE)
```

## Key descriptive values

```{r descriptive-table, message=FALSE, echo=FALSE}
num_summary <- tibble::tibble(
  variable = c("price_dollar", "log_price", "age", "milage_k", "horsepower"),
  median   = c(median(cars$price_dollar), median(cars$log_price), median(cars$age), median(cars$milage_k), median(cars$horsepower)),
  mean     = c(mean(cars$price_dollar), mean(cars$log_price), mean(cars$age), mean(cars$milage_k), mean(cars$horsepower)),
  p25      = c(quantile(cars$price_dollar, 0.25), quantile(cars$log_price, 0.25), quantile(cars$age, 0.25), quantile(cars$milage_k, 0.25), quantile(cars$horsepower, 0.25)),
  p75      = c(quantile(cars$price_dollar, 0.75), quantile(cars$log_price, 0.75), quantile(cars$age, 0.75), quantile(cars$milage_k, 0.75), quantile(cars$horsepower, 0.75)),
  sd       = c(sd(cars$price_dollar), sd(cars$log_price), sd(cars$age), sd(cars$milage_k), sd(cars$horsepower)),
  min      = c(min(cars$price_dollar), min(cars$log_price), min(cars$age), min(cars$milage_k), min(cars$horsepower)),
  max      = c(max(cars$price_dollar), max(cars$log_price), max(cars$age), max(cars$milage_k), max(cars$horsepower))
)

knitr::kable(num_summary, digits = 2, caption = "Key numeric feature summaries")
```

```{r accident-summary, message=FALSE, echo=FALSE}
accident_tbl <- as.data.frame(table(cars$accident), stringsAsFactors = FALSE) |>
  dplyr::rename(accident = Var1, n = Freq) |>
  dplyr::mutate(share = n / sum(n))

knitr::kable(accident_tbl, digits = 2, caption = "Accident history distribution")
```

Median listing sits around \$28k, with the middle 50% between roughly \$15.5k and \$47k, while the maximum reaches \$650k—explaining the heavy right tail. Median age is 9 years (IQR: 6–14), typical mileage is about 63k miles (IQR: 30k–103k), and horsepower clusters around 310 HP (IQR: 248–400). About 28% of cars report an accident or damage, a meaningful factor for pricing.

## Price distribution (raw and log)

```{r price-raw, echo=FALSE, out.width="85%"}
knitr::include_graphics(here("report", "plots", "price_distribution_raw.png"))
```

Raw prices are extremely right-skewed, with most listings below \$80k but a long tail of luxury and exotic vehicles. Modeling on this scale would be dominated by a few high-price outliers.

```{r price-log, echo=FALSE, out.width="85%"}
knitr::include_graphics(here("report", "plots", "price_distribution.png"))
```

Log transformation produces a more bell-shaped distribution and stabilizes variance, making linear-style models and visual comparisons more reliable.

## Depreciation by age and fuel type

```{r age-price, echo=FALSE, out.width="85%"}
knitr::include_graphics(here("report", "plots", "age_vs_price.png"))
```

Prices decline with age across fuels. Electric listings start high but show the sharpest early drop; diesel holds comparatively high prices across ages (though the diesel sample is small), and gasoline sits lower overall.

## Price spread across top brands

```{r brand-price, echo=FALSE, out.width="85%"}
knitr::include_graphics(here("report", "plots", "brand_price_boxplots.png"))
```

Among the 12 most common brands, Porsche leads on median price, followed by Land Rover and Mercedes-Benz; Volume brands (Toyota, Nissan, Jeep) cluster lower with tighter spreads, while some (Chevrolet, Ford) span broader lineups.

## Mileage impact by transmission

```{r milage-price, echo=FALSE, out.width="85%"}
knitr::include_graphics(here("report", "plots", "milage_vs_price.png"))
```

Higher mileage correlates with lower prices. We use a loess smoother (not a straight trendline) and cap the x-axis at 250k miles to reduce the influence of extreme outliers; automatics show a steady decline, and the smaller manual subset is noisier but similar in direction.

## Horsepower premium

```{r hp-price, echo=FALSE, out.width="85%"}
knitr::include_graphics(here("report", "plots", "horsepower_vs_price.png"))
```

Price rises with horsepower, especially from ~250 HP upward; we cap horsepower at 700 to avoid a handful of ultra-high-HP outliers from distorting the loess smoother, so the trend reflects the bulk of the market rather than extreme sports models.

## Accident history effect

```{r accident-price, echo=FALSE, out.width="70%"}
knitr::include_graphics(here("report", "plots", "accident_vs_price.png"))
```

Cars with reported accidents trade at a clear discount relative to clean histories, even after log-scaling prices, confirming accident history as an important predictor.

## 4. Linear regression model


In Section 3 we saw that price is strongly right-skewed and that log(price) has an approximately 
linear relationship with age. Based on this, we now fit a linear regression model with log(price) as response.

The goal is not primarily to build the most accurate predictor, 
but to understand which factors drive used-car prices and in which direction.

We model the natural logarithm of the price instead of the raw price because:

- prices are strictly positive and strongly right–skewed,
- taking the log makes the distribution more symmetric,
- the linear model assumptions (linear relationship, constant variance of the
  residuals) are usually better satisfied on the log scale,
- coefficients can be interpreted approximately as *percentage* effects.


### 4.1. Model specification

We use the feature dataset created in the previous step
(`data/processed/used_cars_features.csv`) and fit the following multiple
linear regression model on the log-price:

`log_price ~ age + milage_k + accident_bin + brand + fuel_type + transmission + ext_col + int_col`

Here

- `log_price` is the natural logarithm of the car price in dollars
  (the target variable / response).
- `age` is the car age in years.
- `milage_k` is the mileage in thousands of miles.
- `accident_bin` is a binary variable  
  (0 = no accident reported, 1 = at least one accident or damage reported).
- `brand`, `fuel_type`, `transmission`, `ext_col` and `int_col` are
  categorical predictors and are represented in the model by dummy variables
  with one reference category each.
- The error term (residual) captures the remaining variation not explained by
  the predictors.

The coefficients of this model measure how much the expected log-price changes
when we increase a numeric predictor by one unit (or switch a dummy variable
from 0 to 1), while *keeping all other variables fixed*.


### 4.2 Estimation and overall performance

We implement and fit the model by sourcing the script
`src/04_model_linear.R`, which

1. loads the feature data (`used_cars_features.csv`),
2. selects the variables listed above and removes rows with missing values,
3. fits the linear model with `stats::lm(...)`, and
4. computes the root mean squared error (RMSE) and \(R^2\) on the log-price
   scale and adds predictions back to the data.

```{r linear-fit, message=FALSE, warning=FALSE}
# Fit the baseline linear regression model and prepare lm_linear_data
source(here::here("src", "04_model_linear.R"))

# Show a compact summary of the model 
broom::tidy(lm_linear) |> 
  dplyr::slice(1:10)  # show only first 10 coefficients

```

```{r linear-metrics, echo=FALSE}
tibble::tibble(
  metric = c("RMSE (log-price)", "R squared (log-price)"),
  value  = c(lm_linear_rmse_log, lm_linear_r2_log)
) |>
  knitr::kable(digits = 3)
```

### 4.3 Interpretation of selected coefficients

Because the model is fitted on the log(price) scale, each coefficient can be
read approximately as a **percentage change in price** when we increase that
variable by one unit (or switch a dummy variable from 0 to 1), while keeping
all other variables fixed. Roughly, a coefficient of −0.06 means “about −6 %”,
a coefficient of +0.20 means “about +22 %”, and so on.

Below we interpret a few selected coefficients from the model.

- **Age (coefficient ≈ −0.058)**  
  Holding all other variables constant, increasing the age of a car by one year
  reduces the expected price by about **6 %** (exp(−0.058) ≈ 0.94).  
  → Older cars are substantially cheaper, as expected.

- **Mileage in thousands (coefficient ≈ −0.006)**  
  An additional 1,000 miles reduces the expected price by roughly **0.6 %**.  
  → The effect of mileage is noticeable but smaller than the effect of age.

- **Accident history (`accident_bin`, coefficient ≈ −0.080)**  
  `accident_bin = 1` indicates that at least one accident or damage has been
  reported. Compared to a car with no accident history (`accident_bin = 0`),
  the expected price is lower by about **8 %**.  
  → Cars with an accident history sell for clearly lower prices.

- **Brand examples**  
  The brand coefficients show how each brand differs from the (omitted)
  reference brand, holding age, mileage, accident history and all other
  variables constant.

  - `brandBMW` (coefficient ≈ 0.28): price is about **30 % higher** than for
    the reference brand.  
    → BMW cars are noticeably more expensive, even after controlling for other
    factors.

  - `brandFerrari` (coefficient ≈ 1.82): price is more than **six times
    higher** (over +500 %) than for the reference brand.  
    → Ferrari appears as an extreme premium brand in this dataset.

- **Fuel type example (`fuel_typeElectric`, coefficient ≈ −0.79)**  
  For purely electric cars, the coefficient corresponds to a price that is
  roughly **55 % lower** than for the reference fuel type, given the same age,
  mileage, brand etc.  
  → In this sample, electric cars are priced clearly below comparable vehicles
  with the reference fuel type (possibly due to different model mix, range
  concerns, or incentives on combustion cars).

- **Transmission (`transmissionManual`, coefficient ≈ 0.20)**  
  Manual transmission has a coefficient of about 0.20, which translates to
  prices that are roughly **20–22 % higher** than for the reference
  transmission type.  
  → Cars with manual transmission are on average more expensive in this sample.

Overall, the signs and magnitudes of the coefficients are plausible: older and
higher-mileage cars and cars with accidents are cheaper, while premium brands
and certain configurations (e.g. BMW, Ferrari) command much higher prices.
With an \(R^2\) of about 0.75 on the log-price scale, the model explains a
large share of the variation in used car prices, even though there is still
substantial unexplained variability.


### 4.4. Relationship between age and log-price

To visualise the effect of age in the linear model, we plot log-price against
age and add a fitted linear trend line.


```{r age-log-plot, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(lm_linear_data,
       aes(x = age, y = log_price)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    x = "Age (years)",
    y = "log(price)",
    title = "Relationship between age and log(price)"
  )
```

The plot shows the expected negative relationship: older cars tend to have a
lower log-price. In our model, the age coefficient is about −0.058, which means
that, holding all other variables constant, one additional year of age reduces
the expected price by roughly 6 % (because exp(−0.058) ≈ 0.94).


### 4.5. Residual diagnostics

To check whether the linear model assumptions are roughly satisfied, we plot the
residuals against the fitted (predicted) log-prices. Ideally, the points are
scattered randomly around zero without a clear pattern.

```{r linear-residual-plot, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(lm_linear_data,
       aes(x = pred_log_price, y = resid_log_price)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    x = "Predicted log(price)",
    y = "Residual (observed - predicted)",
    title = "Residuals vs. predicted values"
  )
```
In our plot, the residuals are roughly centred around zero with no strong
curvature. There is some increase in spread for higher predicted prices, but
overall the linear model assumptions appear acceptable.


### 4.6 Conclusions (linear regression)

Overall, the linear regression on log(price) provides a simple and
interpretable summary of the main price drivers in this dataset. Age and
mileage have the expected negative impact on prices, while an accident
history leads to a price discount of roughly 8 %. Premium brands such as
BMW and especially Ferrari command large price premia, even after
controlling for age, mileage and fuel type. The model explains about
75 % of the variance in log-prices, which is quite high for real-world
data, but the residual plot also shows that there is still substantial
unexplained variability. For a client, this model could already be used
as a rough pricing guideline, but more advanced models (e.g. with
interactions or nonlinear effects) might capture the remaining structure
in the data even better.


## 5. Generalized Linear Model — Binomial (Logistic Regression)

A binomial Generalized Linear Model (GLM) is appropriate when the **response
variable is binary**.  
Here, the response variable is:

- `accident_bin`
  - `1` = car has had at least one reported accident
  - `0` = no reported accident

The model estimates the **probability that a used car has an accident history**
based on vehicle characteristics.

### 5.1 Model specification

We model accident history using a **logistic regression** with a logit link:

\[
\log\left(\frac{P(\text{accident}=1)}{1 - P(\text{accident}=1)}\right)
= \beta_0 + \beta_1 X_1 + \dots + \beta_p X_p
\]

Model formula:

`accident_bin ~ brand + age + milage_k + fuel_type + transmission +
price_dollar + horsepower + cylinders`

- **Response**: `accident_bin` (binary)
- **Predictors**:
  - Continuous: age, mileage (1,000 miles), price, horsepower, cylinders
  - Categorical: brand, fuel type, transmission
- **Link function**: logit


### 5.2 Model fitting and summary

```{r glm-fit, message=FALSE, warning=FALSE}
# Source the script that fits the binomial GLM
source(here::here("src", "05_model_glm_binomial.R"))

# Show a full summary of the model 
summary(glm.car)
```

### 5.3 Key Odds Ratios and Interpretation

We scale and exponentiate the coefficients of the binomial GLM to obtain **odds ratios**, which show how the odds of a car having an accident history change with each predictor.

To improve interpretability, continuous predictors are rescaled before computing odds ratios. This rescaling does not affect statistical significance or model fit, only the unit of interpretation.

The data were scaled as follows:

- `milage_k` was multiplied by 10.
- `price_dollar` was multiplied by 1,000.
- `horsepower` was multiplied by 50.

```{r glm-key-odds, message=FALSE, echo=FALSE, warning=FALSE}

#Key predictors
key_terms <- c("milage_k", "price_dollar", "horsepower", "fuel_typeElectric")

#Scaling factors for interpretability
scales <- c(milage_k = 10, # 10k miles
price_dollar = 1000, # $1000
horsepower = 50, # 50 HP
fuel_typeElectric = 1) # dummy variable

#Compute odds ratios with scaling
glm_key_odds <- broom::tidy(glm.car) %>%
filter(term %in% key_terms) %>%
rowwise() %>%
mutate(
scaled_estimate = estimate * scales[term],
odds_ratio = exp(scaled_estimate),
pct_change = ifelse(odds_ratio > 1,
(odds_ratio - 1) * 100, # percent increase
(1 - odds_ratio) * -100), # percent decrease
signif = case_when(
p.value < 0.001 ~ "",
p.value < 0.01 ~ "",
p.value < 0.05 ~ "",
p.value < 0.1 ~ ".",
TRUE ~ ""
)
) %>%
select(term, odds_ratio, pct_change, p.value, signif)

# Show table
knitr::kable(glm_key_odds, digits = 3, caption = "GLM Binomial: Key Odds Ratios and Percent Change (scaled)")
```

**Interpretation of key predictors:**

- **Mileage (`milage_k`)**: Odds ratio > 1 → Higher mileage slightly increases the odds of a reported accident. Specifically, an additional 10,000 miles increases the odds by ~7%, reflecting increased usage and exposure.  

- **Price (`price_dollar`)**: Odds ratio < 1 → Higher-priced vehicles are less likely to have an accident. Each additional $1,000 reduces the odds by ~2%, suggesting that more expensive cars are generally newer or better maintained.  

- **Horsepower (`horsepower`)**: Odds ratio > 1 → More powerful cars slightly increase accident odds. For example, a 50 HP increase raises the odds by ~9.5%, possibly due to more spirited driving.

- **Fuel type – Electric (`fuel_typeElectric`)**: Odds ratio << 1 → Electric cars have substantially lower odds (≈ 72 % lower) of reported accidents compared to the reference fuel type. This effect should be interpreted cautiously, as electric vehicles in this dataset are generally newer and may benefit from modern safety technologies.

These odds ratios allow for an intuitive interpretation of how each variable affects accident probability, holding all other variables constant. Most other predictors (brand, transmission, cylinders, age) were not statistically significant in this model.

### 5.4 Conclusions (Binomial GLM)

The binomial GLM indicates that accident probability is primarily driven by vehicle usage and value. Higher mileage and higher horsepower are associated with increased accident odds, while higher-priced cars are less likely to have a reported accident history. This is consistent with the intuition that cheaper cars tend to be older, more heavily used, and exposed to greater wear and risk. Electric vehicles exhibit substantially lower accident odds in the model. However, this result is likely influenced by sample composition: electric cars in the dataset are generally newer and therefore have had less exposure time to accidents. The observed fuel-type effect may therefore partially reflect vehicle age rather than an intrinsic safety advantage. Overall, the GLM provides a transparent and interpretable baseline model for accident risk. Its linear structure, however, limits its ability to capture nonlinear exposure effects, motivating the use of a Generalised Additive Model in the next section.


## 6. Generalized Linear Model — Poisson

A Poisson GLM is typically used when the **response variable is a count**
(non-negative integers). Because this dataset does not contain a natural event
count, we use a pragmatic proxy: **mileage in thousands** (`milage_k`),
converted to an integer “count-like” variable (`milage_k_count`).  
This section mainly demonstrates the **Poisson GLM workflow and interpretation**.

### 6.1 Model specification

We model the expected mileage count (in thousands) using a Poisson GLM with a log link:

`milage_k_count ~ age + accident_bin + brand + fuel_type + transmission + ext_col + int_col`

In a Poisson GLM with log link:

- Response: `milage_k_count` (non-negative integer proxy)
- Predictors: age, accident history, and categorical vehicle characteristics
- Link: `log( E[milage_k_count] ) = linear predictor`

So coefficients are interpreted **multiplicatively**:  
`exp(beta)` is the factor change in the expected count for a one-unit increase (or dummy switch),
holding other variables fixed.

### 6.2 Estimation and overall performance

We fit the Poisson GLM by sourcing `src/06_model_glm_poisson.R`, which:
1) loads the feature data,  
2) creates `milage_k_count`,  
3) fits a Poisson GLM with log link, and  
4) adds predictions/residuals back to the data.

```{r poisson-fit, message=FALSE, warning=FALSE}
source(here::here("src", "06_model_glm_poisson.R"))

# compact coefficient table incl. significance stars
poisson_tbl <- broom::tidy(glm_poisson) |>
  dplyr::mutate(
    signif = dplyr::case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01  ~ "**",
      p.value < 0.05  ~ "*",
      p.value < 0.1   ~ ".",
      TRUE            ~ ""
    )
  )

poisson_tbl |>
  dplyr::select(term, estimate, std.error, statistic, p.value, signif) |>
  dplyr::slice(1:12)
```

```{r poisson-metrics, echo=FALSE, message=FALSE, warning=FALSE}
pseudo_r2 <- 1 - (glm_poisson$deviance / glm_poisson$null.deviance)
dispersion <- sum(stats::residuals(glm_poisson, type = "pearson")^2) / glm_poisson$df.residual
aic_val <- AIC(glm_poisson)

data.frame(
  AIC = aic_val,
  pseudo_R2_deviance = pseudo_r2,
  dispersion_pearson = dispersion
)
```

If the **dispersion** is clearly above 1, the Poisson variance assumption
(mean ≈ variance) may be violated (overdispersion). In a real use case you’d
consider a quasi-Poisson or negative binomial model. We keep Poisson here for
comparability and interpretation practice.

### 6.3 Interpretation of selected coefficients

In a Poisson GLM with log link:

- `exp(beta) > 1` → expected count increases  
- `exp(beta) < 1` → expected count decreases  
- percent change: `(exp(beta) - 1) * 100`

```{r poisson-effects, echo=FALSE, message=FALSE, warning=FALSE}
effects_tbl <- broom::tidy(glm_poisson) |>
  dplyr::mutate(
    rate_ratio = exp(estimate),
    pct_change = (rate_ratio - 1) * 100
  )

selected_terms <- c("age", "accident_bin", "transmissionManual", "fuel_typeElectric")

effects_tbl |>
  dplyr::filter(term %in% selected_terms) |>
  dplyr::select(term, estimate, rate_ratio, pct_change, p.value) |>
  dplyr::mutate(
    rate_ratio = round(rate_ratio, 3),
    pct_change = round(pct_change, 1)
  )
```

### 6.4 Residual diagnostics

```{r poisson-residual-plot, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(glm_poisson_data, aes(x = pred_milage_k, y = resid_milage_k)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    x = "Predicted milage_k_count",
    y = "Residual (observed - predicted)",
    title = "Poisson GLM: residuals vs. predicted values"
  )
```

### 6.5 Conclusions (Poisson GLM)

The Poisson GLM demonstrates how to model a count-like response with a log link
and interpret effects as multiplicative changes via `exp(beta)`. While
`milage_k_count` is not a true event count, this workflow is useful to practice
GLM estimation, interpretation, and basic diagnostics. In a real client setting
with genuine count outcomes, overdispersion should be checked carefully and a
quasi-Poisson or negative binomial model may be more appropriate.


## 7. Generalised Additive Model (GAM)

To relax the linearity assumption of the binomial GLM, we fit a **Generalised Additive Model (GAM)** to predict whether a car has had at least one reported accident (accident_bin). The GAM allows for **non-linear relationships** between key continuous predictors and accident probability, while retaining interpretable parametric effects for categorical variables. 

### 7.1 Model specification

We model accident history using a GAM with a binomial family and logit link:

`accident_bin ~ brand + fuel_type + transmission + cylinders + s(milage_k) + s(price_dollar) + s(horsepower) + s(age)`

Where:
- `accident_bin` is a binary response (0 = no reported accident, 1 = at least one reported accident).
- `brand`, `fuel_type`, and `transmission` are categorical predictors.
- `cylinders` enters the model linearly.
- `s(milage_k)`, `s(price_dollar)`, `s(horsepower)`, and `s(age)` are smooth
  spline functions capturing potential nonlinear effects.
- The model is estimated using penalised likelihood with REML.

### 7.2 Model fitting and summary

Smoothness is selected automatically via REML, reducing the risk of overfitting despite flexible spline terms.

```{r gam-accident-fit, message=FALSE, warning=FALSE}
source(here::here("src", "07_model_gam.R"))

# Show a full summary of the model
summary(gam.car)
```

The summary output reports estimated degrees of freedom (EDF) and approximate significance tests for each smooth term.

### 7.3 Interpretation of smooth effects

The GAM summary reports estimated degrees of freedom (EDF) and significance
tests for each smooth term, indicating whether nonlinear effects are present.

- **Mileage (`s(milage_k)`)**  
  Mileage shows a **highly significant and strongly nonlinear effect** on
  accident probability (EDF ≈ 5.7, p < 2e−16). The relatively large EDF indicates
  a complex relationship: accident risk does not increase at a constant rate
  with mileage. Instead, the effect varies across usage levels, reflecting
  changing exposure and driving patterns over a vehicle’s lifetime.

- **Price (`s(price_dollar)`)**  
  Price has a **statistically significant smooth effect** (EDF ≈ 2.3,
  p = 0.0028). While the effect is nonlinear, its lower EDF suggests a shape
  close to linear. Higher-priced vehicles tend to have a lower probability of
  reported accidents, consistent with newer vehicles, better maintenance, and
  improved safety features.

- **Horsepower (`s(horsepower)`)**  
  The smooth effect of horsepower is **not statistically significant**
  (p = 0.216). Although horsepower is modelled flexibly, the data provide no
  strong evidence that engine power independently affects accident probability
  once mileage, price, and other characteristics are controlled for.

- **Age (`s(age)`)**  
  The smooth effect of age is **marginally insignificant** (p = 0.078). This
  suggests that age alone does not strongly predict accident probability after
  accounting for mileage and vehicle characteristics. Much of the age-related
  risk appears to be captured indirectly through mileage.

Overall, mileage and price emerge as the most important nonlinear predictors of
accident history in the GAM.

### 7.4 Interpretation of parametric effects

The parametric terms (brand, fuel type, transmission, and cylinders) are
interpreted as in a standard logistic regression, holding all smooth effects
constant.

- **Brand effects**  
  Most brand coefficients are not statistically significant, indicating limited
  brand-specific differences in accident probability after controlling for
  mileage, price, and other variables. One exception is **MINI**, which shows a
  significantly lower accident probability compared to the reference brand
  (p = 0.044).

- **Fuel type**  
  Fuel type coefficients are not statistically significant. Electric vehicles
  show a negative coefficient, suggesting lower accident odds, but this effect
  is not significant once nonlinear mileage and price effects are accounted for.

- **Transmission**  
  Manual transmission does not have a statistically significant effect on
  accident probability in this model.

- **Cylinders**  
  The number of cylinders enters linearly and is not statistically significant,
  suggesting little direct impact on accident risk.

Overall, categorical vehicle characteristics play a secondary role compared to
usage-related variables such as mileage and price.

### 7.5 Conclusions (GAM)

The Generalised Additive Model identifies mileage as the dominant predictor of accident risk, showing a highly significant and nonlinear relationship with the probability of reported accidents. Vehicle price also matters: lower-priced cars are more likely to have had accidents. Other continuous predictors, including horsepower and age, show no strong independent effects once the nonlinear patterns of mileage and price are accounted for. Most categorical variables brand, fuel type, transmission, and cylinders are not statistically significant, suggesting that accident risk is driven primarily by usage intensity and vehicle value, rather than brand identity. Compared to the linear binomial GLM, the GAM captures nonlinear effects and provides a more nuanced and interpretable view of accident risk, although overall predictive power remains limited due to the inherent randomness of accidents. 




## 8. SVM model (regression)
We fit Support Vector Machine (SVM) regression models to predict `log_price`. We used two libraries: `e1071` and `kernlab` (via `caret::train`). 
Both models employ a radial kernel to capture non-linear relationships in the data.

### 8.1 Model specification
1.  Loads the engineered car data (used_cars_features.csv) and keep the predictors plus `log_price` target.
2.  Splits the data `80/20` into train/test (seeded for reproducibility).
3.  Defines a helper to compute RMSE/MAE/R² .
4.  Fits two radial SVM regressors:
    - `e1071` svm tuned over a small cost/gamma grid with cross validation. 3-fold cross validation inside tune() selects the best combo on the training split.
    - `caret/kernlab` + `svmRadial` tuned over a small C/sigma grid with 3-fold cross validation.
5. Predict on the held-out test set for each model, compute metrics, and save:
- Models (svm_log_price_e1071.rds, svm_log_price_kernlab.rds)
- Test predictions (per model CSVs)
- Combined metrics RMSE, MAE, R² (svm_log_price_metrics.csv)

### 8.2 Cross-validation

`e1071` As you see on the heatmap, some areas have similar green shades, indicating comparable performance across those parameter combinations. However,
the lowest RMSE for e1071 was achieved with following parameters: cost=4, gamma=0.05 (CV RMSE=0.2846) 

```{r svm-heatmap, echo=FALSE, out.width="60%"}
knitr::include_graphics(here("report", "models", "svm", "svm_tuning_heatmap.png"))
```

`caret/kernlab` And here you can see best kernlab parameters: C=2, sigma=0.01 (CV RMSE=0.4298)
```{r svm-heatmap-caret, echo=FALSE, out.width="60%"}
knitr::include_graphics(here("report", "models", "svm", "svm_tuning_heatmap_caret.png"))
```



### 8.2 RMSE/MAE/R² on test split
The radial Support Vector Machine from the e1071 package performs best, showing the smallest average prediction error (RMSE ≈ 0.29) and explaining about 87% of the variation in used-car prices, outperforming the alternative SVM model. SVMs do not yield straightforward coefficient interpretations; they learn support vectors and decision functions in a transformed feature space. 
```{r svm-metrics, message=FALSE, echo=FALSE, warning=FALSE}
svm_metrics <- readr::read_csv(
  here("report", "models", "svm", "svm_log_price_metrics.csv"),
  show_col_types = FALSE
)

svm_best <- readr::read_lines(here("report", "models", "svm", "svm_best_model.txt"))[1]

svm_metrics_wide <- svm_metrics |>
  tidyr::pivot_wider(names_from = .metric, values_from = .estimate)

knitr::kable(svm_metrics_wide, digits = 3, caption = "Test metrics for SVM variants (target: log_price)")
```


### 8.3 Interpretation of results

Both models show strong agreement between predicted and true prices, with points clustering closely around the diagonal and the smooth curve largely overlapping the ideal line, indicating good calibration and limited systematic bias. Slight over-prediction is visible for very low-priced cars and mild under-prediction for the most expensive vehicles, a common pattern in pricing problems. The e1071 radial SVM exhibits marginally tighter clustering and smoother alignment with the diagonal, consistent with its lower RMSE and higher R².
```{r svm-pred-vs-true, fig.width=11, fig.height=5.5, message=FALSE, echo=FALSE}
pred_e1071 <- readr::read_delim(
  here("report", "models", "svm", "svm_log_price_e1071_predictions.csv"),
  delim = ";",
  show_col_types = FALSE
) |>
  dplyr::mutate(model = "e1071_radial")

pred_kern <- readr::read_delim(
  here("report", "models", "svm", "svm_log_price_kernlab_predictions.csv"),
  delim = ";",
  show_col_types = FALSE
) |>
  dplyr::mutate(model = "kernlab_radial")

plot_svm <- function(df, title) {
  df <- df |>
    dplyr::mutate(resid = pred_log_price - log_price)

  ggplot2::ggplot(df, ggplot2::aes(x = log_price, y = pred_log_price, color = resid)) +
    ggplot2::geom_point(alpha = 0.7, size = 1.4) +
    ggplot2::geom_smooth(method = "loess", se = FALSE, color = "black", linewidth = 0.8) +
    ggplot2::geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray40") +
    ggplot2::coord_equal() +
    ggplot2::scale_color_gradient2(
      low = "#B91C1C", mid = "#CBD5E1", high = "#15803D",
      midpoint = 0,
      name = "Residual price (pred - true)\nred = under, grey = near, green = over\n"
    ) +
    ggplot2::labs(
      title = title,
      x = "True log(price)",
      y = "Predicted log(price)"
    ) +
    ggplot2::theme_minimal(base_size = 12) +
    ggplot2::theme(
      legend.position = "none",
      plot.title.position = "plot",
      plot.title = ggplot2::element_text(hjust = 0, vjust= -20)
    )
}

p1 <- plot_svm(pred_e1071, "e1071 radial SVM:\n predicted vs true")
p2 <- plot_svm(pred_kern, "kernlab radial SVM:\n predicted vs true")

# Standalone legend using the same residual scale
legend_plot <- ggplot2::ggplot(
  data.frame(resid = c(-0.5, 0, 0.5), x = 1, y = 1),
  ggplot2::aes(x = x, y = y, color = resid)
) +
  ggplot2::geom_point(alpha = 0) + # invisible points; legend only
  ggplot2::scale_color_gradient2(
    low = "#B91C1C", mid = "#CBD5E1", high = "#15803D",
    midpoint = 0,
    name = "Residual (pred - true)\nred = under, grey = near, green = over\nDashed line: perfect prediction\nBlack curve: average prediction behaviour"
  ) +
  ggplot2::guides(color = ggplot2::guide_colorbar(
    barheight = unit(60, "pt"),
    title.theme = ggplot2::element_text(size = 12),
    label.theme = ggplot2::element_text(size = 11)
  )) +
  ggplot2::theme_void() +
  ggplot2::theme(
    legend.position = "right"
  )

patchwork::wrap_plots(
  p1,
  p2,
  legend_plot,
  ncol = 3,
  widths = c(1, 1, 0.22)
)
```

## 9. Neural network model (regression)
We fit two neural networks to predict `log_price`: a caret `nnet` with preprocessing/tuning and a manual `neuralnet` with a shallow hidden layer.

### 9.1 Model specification
- Load the engineered data and keep predictors plus `log_price`.
- Split 80/20 into train/test (seeded).
- caret `nnet`: recipe with dummy variables + zero-variance filter + centering/scaling; 3-fold cross validation over a small size/decay grid; `maxit=300`.
- manual `neuralnet`: one hidden layer (4 units) on scaled/dummified matrix, with optional subsampling for speed.
- Save models, per-model predictions, and combined metrics to `report/models/nn`.

### 9.2 Cross-validation
- caret tuning uses 3-fold cross validation on the training split to choose size/decay; the manual `neuralnet` uses fixed architecture (no CV tuning).
- CV metrics come from training folds; test metrics come from the untouched 20% hold-out.
- Only one heatmap is shown because only the caret model does a grid search; the manual neuralnet keeps a single, simple layout without tuning.

Best caret grid point: `size = 5`, `decay = 0.001` (CV RMSE ≈ 0.372). The white/black marker on the heatmap highlights this combination.

```{r nn-heatmap-caret, echo=FALSE, out.width="60%"}
knitr::include_graphics(here("report", "models", "nn", "nn_tuning_heatmap_caret.png"))
```

### 9.3 RMSE/MAE/R² on test split
The caret-based neural network performs better than the manually specified variant, achieving a smaller average prediction error (RMSE ≈ 0.37) and explaining about 79% of the variation in used-car prices (R² ≈ 0.79). The manually specified neural network shows weaker predictive performance, with larger errors (RMSE ≈ 0.41) and a lower proportion of explained variance (R² ≈ 0.74). Neural networks do not provide easily interpretable coefficients; instead, they learn complex non-linear relationships between vehicle characteristics and prices through layered transformations.
```{r nn-metrics, message=FALSE, echo=FALSE}
nn_metrics <- readr::read_csv(
  here("report", "models", "nn", "nn_log_price_metrics.csv"),
  show_col_types = FALSE
)

nn_best <- readr::read_lines(here("report", "models", "nn", "nn_best_model.txt"))[1]

nn_metrics_wide <- nn_metrics |>
  tidyr::pivot_wider(names_from = .metric, values_from = .estimate)

knitr::kable(nn_metrics_wide, digits = 3, caption = "Test metrics for NN variants (target: log_price)")
```

### 9.4 Interpretation of results
Both neural network models capture the strong relationship between observed and predicted log-transformed prices, indicating that the main structure of the data is well learned. Predictions are generally accurate across the central price range, where most observations lie, with limited overall bias.

The caret-based neural network shows more stable and consistent performance across different price levels. In contrast, the manually specified neural network exhibits greater variability in its predictions, particularly for higher-priced vehicles, where underestimation is more pronounced.

Overall, while both neural networks perform well, the caret implementation delivers more reliable predictions across the full price range and is therefore preferred in this analysis.
```{r nn-pred-vs-true, fig.width=11, fig.height=5.5, message=FALSE, echo=FALSE}
pred_caret <- readr::read_delim(
  here("report", "models", "nn", "nn_log_price_caret_predictions.csv"),
  delim = ";",
  show_col_types = FALSE
) |>
  dplyr::mutate(model = "caret_nnet")

pred_manual <- readr::read_delim(
  here("report", "models", "nn", "nn_log_price_neuralnet_predictions.csv"),
  delim = ";",
  show_col_types = FALSE
) |>
  dplyr::mutate(model = "neuralnet_manual")

plot_nn <- function(df, title) {
  df <- df |>
    dplyr::mutate(resid = pred_log_price - log_price)

  ggplot2::ggplot(df, ggplot2::aes(x = log_price, y = pred_log_price, color = resid)) +
    ggplot2::geom_point(alpha = 0.7, size = 1.4) +
    ggplot2::geom_smooth(method = "loess", se = FALSE, color = "black", linewidth = 0.8) +
    ggplot2::geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray40") +
    ggplot2::coord_equal() +
    ggplot2::scale_color_gradient2(
      low = "#B91C1C", mid = "#CBD5E1", high = "#15803D",
      midpoint = 0,
      name = "Residual (pred - true)\nred = under-prediction, grey = near, green = over-prediction\nDashed line: perfect prediction\nBlack curve: average prediction behaviour"
    ) +
    ggplot2::labs(
      title = title,
      x = "True log(price)",
      y = "Predicted log(price)"
    ) +
    ggplot2::theme_minimal(base_size = 12) +
    ggplot2::theme(
      legend.position = "none",
      plot.title.position = "plot",
      plot.title = ggplot2::element_text(hjust = 0, vjust= -20)
    )
}

p1 <- plot_nn(pred_caret, "caret nnet: predicted vs true")
p2 <- plot_nn(pred_manual, "neuralnet manual: predicted vs true")

legend_plot_nn <- ggplot2::ggplot(
  data.frame(resid = c(-0.5, 0, 0.5), x = 1, y = 1),
  ggplot2::aes(x = x, y = y, color = resid)
) +
  ggplot2::geom_point(alpha = 0) +
  ggplot2::scale_color_gradient2(
    low = "#B91C1C", mid = "#CBD5E1", high = "#15803D",
    midpoint = 0,
    name = "Residual (pred - true)\nred = under-prediction, grey = near, green = over-prediction\nDashed line: perfect prediction\nBlack curve: average prediction behaviour"
  ) +
  ggplot2::guides(color = ggplot2::guide_colorbar(
    barheight = unit(60, "pt"),
    title.theme = ggplot2::element_text(size = 12),
    label.theme = ggplot2::element_text(size = 11)
  )) +
  ggplot2::theme_void() +
  ggplot2::theme(
    legend.position = "right"
  )

patchwork::wrap_plots(
  p1,
  p2,
  legend_plot_nn,
  ncol = 3,
  widths = c(1, 1, 0.22)
)
```


## 10. Model Comparison – Accident History  
*(Binomial GLM vs. Binomial GAM)*

Because `accident_bin` is a binary outcome, we compare only models suitable for
classification: the **binomial GLM (logistic regression)** and the
**binomial GAM**. Both models were trained on the same feature set and evaluated
on the same train/test split.

### 10.1 Evaluation metrics

```{r accident-test-compare, message=FALSE, echo=FALSE}
features_path <- here("data", "processed", "used_cars_features.csv")
cars <- readr::read_delim(features_path, delim = ";", show_col_types = FALSE)


# --- 1. Create train and test set (20% of data) ---
set.seed(123)  # reproducible
indices <- sample(seq_len(nrow(cars)), size = 0.2 * nrow(cars)) # 20% of rows for testing
test_accident <- cars[indices, ]
train_accident <- cars[-indices, ]

# --- 2. Fit model
glm.car.cv <- glm(accident_bin ~ brand + age + milage_k + fuel_type + transmission + price_dollar + horsepower + cylinders, 
                  data = train_accident,
                  family = binomial)

gam.car.cv <- mgcv::gam(accident_bin ~ brand + fuel_type + transmission + 
                          cylinders + s(milage_k) + s(price_dollar) + s(horsepower) + s(age), 
                        data = train_accident,
                        family = binomial)

# --- 3. Predict accident probabilities ---
glm_prob <- predict(glm.car.cv, newdata = test_accident, type = "response")
gam_prob <- predict(gam.car.cv, newdata = test_accident, type = "response")

# --- 4. Class predictions (0.5 threshold) ---
glm_pred <- ifelse(glm_prob > 0.5, 1, 0)
gam_pred <- ifelse(gam_prob > 0.5, 1, 0)

# --- 5. Evaluation metrics ---
# Accuracy
glm_acc <- mean(glm_pred == test_accident$accident_bin)
gam_acc <- mean(gam_pred == test_accident$accident_bin)

# AUC
glm_auc <- auc(test_accident$accident_bin, glm_prob)
gam_auc <- auc(test_accident$accident_bin, gam_prob)

# --- 6. Combine results into table ---
accident_comp <- tibble(
  Model = c("Binomial GLM", "Binomial GAM"),
  Accuracy = c(glm_acc, gam_acc),
  AUC = c(as.numeric(glm_auc), as.numeric(gam_auc))
)

# --- 7. Display table ---
knitr::kable(accident_comp, digits = 3,
             caption = "Predictive performance for accident history models (20% random test set)")
```

### 10.2 Interpretation

The binomial GAM slightly outperforms the GLM (Accuracy 0.728 vs. 0.724; AUC 0.707 vs. 0.704) by capturing nonlinear effects in the data. The GLM provides a simple, interpretable baseline, while the GAM offers a more flexible model that better fits the patterns in accident history.




